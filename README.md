# Emotion Recognition from Facial Expressions

ğŸ¯ Ce projet utilise un modÃ¨le de rÃ©seau de neurones convolutionnels (CNN) pour la reconnaissance des Ã©motions Ã  partir des expressions faciales. Le modÃ¨le est entraÃ®nÃ© sur le dataset **FER-2013** et utilise OpenCV pour capturer des images Ã  partir de la webcam et dÃ©tecter les Ã©motions en temps rÃ©el.

## PrÃ©requis âš™ï¸

Avant de commencer, assurez-vous d'avoir les outils suivants installÃ©s :

- ğŸ Python 3.x
- ğŸ–¼ï¸ OpenCV
- ğŸ¤– TensorFlow
- ğŸ¤– Keras
- ğŸ“Š Pandas
- ğŸ“ˆ Matplotlib
- ğŸ” Scikit-learn
- ğŸ”¢ Numpy

Vous pouvez installer les dÃ©pendances nÃ©cessaires avec la commande suivante :

```bash
pip install opencv-python tensorflow pandas matplotlib scikit-learn numpy
```
## Structure du projet ğŸ“
### Le projet est divisÃ© en deux parties principales :

#### 1. EntraÃ®nement du modÃ¨le 
Dans cette partie, nous entraÃ®nons un modÃ¨le de reconnaissance des Ã©motions basÃ© sur les expressions faciales. Le modÃ¨le est entraÃ®nÃ© sur les donnÃ©es du fichier fer2013.csv, qui contient 35 000 images de visages Ã©tiquetÃ©es avec 7 Ã©motions diffÃ©rentes.

#### 2. DÃ©tection des Ã©motions en temps rÃ©el via la webcam
Dans cette partie, nous chargeons le modÃ¨le prÃ©alablement entraÃ®nÃ© et utilisons OpenCV pour dÃ©tecter les visages dans un flux vidÃ©o provenant de la webcam. Le modÃ¨le prÃ©dit l'Ã©motion Ã  partir des expressions faciales dÃ©tectÃ©es et l'affiche en temps rÃ©el.

## Fonctionnement du projet ğŸ§ 
### EntraÃ®nement du modÃ¨le ğŸ‹ï¸ :

Le modÃ¨le est un rÃ©seau de neurones convolutionnels qui prend en entrÃ©e des images de visages (48x48 pixels en niveaux de gris).
Le modÃ¨le est entraÃ®nÃ© sur le dataset FER-2013 pour reconnaÃ®tre 7 Ã©motions diffÃ©rentes :

ğŸ˜¡ ColÃ¨re
ğŸ¤¢ DÃ©goÃ»t
ğŸ˜¨ Peur
ğŸ˜„ Joie
ğŸ˜¢ Tristesse
ğŸ˜² Surprise
ğŸ˜ Neutre

### DÃ©tection en temps rÃ©el via la webcam ğŸ“¸ :

Une fois le modÃ¨le entraÃ®nÃ©, vous pouvez l'utiliser pour prÃ©dire les Ã©motions Ã  partir des visages dÃ©tectÃ©s dans un flux vidÃ©o en temps rÃ©el.
Le modÃ¨le prÃ©dit l'Ã©motion du visage et affiche le label de l'Ã©motion sur l'image en temps rÃ©el.

## Comment exÃ©cuter le projet ğŸš€
#### EntraÃ®ner le modÃ¨le ğŸ”¨ :

ExÃ©cutez le script d'entraÃ®nement pour entraÃ®ner le modÃ¨le sur le dataset FER-2013 :
```bash
python train_model.py
```
Cela entraÃ®nera le modÃ¨le et le sauvegardera sous le nom modele_emotion.h5.

#### DÃ©tection des Ã©motions via la webcam ğŸ–¥ï¸ :

Une fois le modÃ¨le entraÃ®nÃ©, vous pouvez lancer le script de dÃ©tection en temps rÃ©el :
```bash
python detect_emotions.py
```
Le programme ouvrira la webcam et affichera l'Ã©motion prÃ©dite pour chaque visage dÃ©tectÃ©.

## RÃ©sultats attendus ğŸ“Š
Le programme de dÃ©tection des Ã©motions via la webcam devrait Ãªtre capable de reconnaÃ®tre les Ã©motions Ã  partir des expressions faciales.
Le modÃ¨le peut Ãªtre amÃ©liorÃ© avec plus de donnÃ©es ou des techniques d'augmentation de donnÃ©es pour augmenter la prÃ©cision.

## Contributions ğŸ¤
Les contributions Ã  ce projet sont les bienvenues ! Si vous avez des suggestions ou des amÃ©liorations Ã  apporter, n'hÃ©sitez pas Ã  ouvrir une issue ou Ã  soumettre une pull request.

## Licence ğŸ“œ
Ce projet est sous licence MIT - voir le fichier LICENSE pour plus de dÃ©tails.
